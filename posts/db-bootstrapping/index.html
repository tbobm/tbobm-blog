<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Bootstrapping SQL databases for local and production setup | tbobm.dev</title>
<meta name=keywords content="tech,database,rbac,postgres,migration"><meta name=description content="A practical walkthrough of how I manage SQL databases across dev and prod - from local Docker setups to CI/CD-powered migrations in the cloud.
Intro When working with databases, it’s easy to fall into the trap of taking shortcuts — a quick container here, a few clicks in the AWS console there, and before you know it, you&rsquo;re running production off an unversioned schema with the master user.
This article is a hands-on guide—and a collection of things I’ve grown to enjoy when working with SQL databases in modern environments."><meta name=author content='Theo "Bob" Massard'><link rel=canonical href=https://blog.tbobm.dev/posts/db-bootstrapping/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.tbobm.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.tbobm.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.tbobm.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.tbobm.dev/apple-touch-icon.png><link rel=mask-icon href=https://blog.tbobm.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.tbobm.dev/posts/db-bootstrapping/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-TH8WFGGJBS"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-TH8WFGGJBS")}</script><meta property="og:title" content="Bootstrapping SQL databases for local and production setup"><meta property="og:description" content="A practical walkthrough of how I manage SQL databases across dev and prod - from local Docker setups to CI/CD-powered migrations in the cloud.
Intro When working with databases, it’s easy to fall into the trap of taking shortcuts — a quick container here, a few clicks in the AWS console there, and before you know it, you&rsquo;re running production off an unversioned schema with the master user.
This article is a hands-on guide—and a collection of things I’ve grown to enjoy when working with SQL databases in modern environments."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.tbobm.dev/posts/db-bootstrapping/"><meta property="og:image" content="https://blog.tbobm.dev/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-18T21:30:00+02:00"><meta property="article:modified_time" content="2025-04-18T21:30:00+02:00"><meta property="og:site_name" content="tbobm.dev"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.tbobm.dev/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Bootstrapping SQL databases for local and production setup"><meta name=twitter:description content="A practical walkthrough of how I manage SQL databases across dev and prod - from local Docker setups to CI/CD-powered migrations in the cloud.
Intro When working with databases, it’s easy to fall into the trap of taking shortcuts — a quick container here, a few clicks in the AWS console there, and before you know it, you&rsquo;re running production off an unversioned schema with the master user.
This article is a hands-on guide—and a collection of things I’ve grown to enjoy when working with SQL databases in modern environments."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.tbobm.dev/posts/"},{"@type":"ListItem","position":2,"name":"Bootstrapping SQL databases for local and production setup","item":"https://blog.tbobm.dev/posts/db-bootstrapping/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Bootstrapping SQL databases for local and production setup","name":"Bootstrapping SQL databases for local and production setup","description":"A practical walkthrough of how I manage SQL databases across dev and prod - from local Docker setups to CI/CD-powered migrations in the cloud.\nIntro When working with databases, it’s easy to fall into the trap of taking shortcuts — a quick container here, a few clicks in the AWS console there, and before you know it, you\u0026rsquo;re running production off an unversioned schema with the master user.\nThis article is a hands-on guide—and a collection of things I’ve grown to enjoy when working with SQL databases in modern environments.","keywords":["tech","database","rbac","postgres","migration"],"articleBody":"A practical walkthrough of how I manage SQL databases across dev and prod - from local Docker setups to CI/CD-powered migrations in the cloud.\nIntro When working with databases, it’s easy to fall into the trap of taking shortcuts — a quick container here, a few clicks in the AWS console there, and before you know it, you’re running production off an unversioned schema with the master user.\nThis article is a hands-on guide—and a collection of things I’ve grown to enjoy when working with SQL databases in modern environments. It covers setting up Postgres 1 both locally and in the cloud, adopting schema as code using Atlas, securing access with proper roles, and maintaining everything through GitHub Actions.\nThe goal is to keep your database setup repeatable, reviewable, and resilient from day one.\nInfra as Code, Schema as Code, Everything as Code When working with databases, consistency and repeatability are key. Whether setting up a local development database or provisioning a production-ready environment, managing infrastructure and schema as code ensures a predictable and maintainable setup.\nLet’s explore why this approach matters and how tools like AtlasGO simplify schema management.\nWhy yet another tool? There are plenty of database migration tools out there, like Alembic that I’ve used in the past but I love AtlasGO for a few reasons:\nSchema as Code: unlike imperative migration tools, AtlasGO takes a declarative approach, allowing you to define your schema in a structured format. Leverages HCL: it uses HashiCorp Configuration Language (HCL), the same format used by (my dear) Terraform and Packer, making it easier to integrate with existing infrastructure as code workflows. No dependecy on a language dependency: many tools require Python 2, Java, or SQL-based scripting. AtlasGO avoids this, keeping the setup lightweight and easy to use. Easy to replicate and review: having a single source of truth for schema definitions makes collaboration, code reviews, and automation seamless. No ClickOps: I strongly dislike manual UI-based configurations (aka ClickOps). They lead to inconsistencies and make infrastructure difficult to track and reproduce.\nWhat this means in practice?\nBy adopting a declarative approach, we gain:\nPredictability: changes are explicit and version-controlled.\nAutomation: infrastructure and schema changes can be applied programmatically.\nScalability: the same process can be used across local, staging, and production environments.\nIn the next section, we’ll get hands-on with [AtlasGO][atlas-main], defining an initial schema and managing database migrations efficiently.\nEmbrace schema as code Initial schema declaration:\nWhen starting with schema as code, you can either:\nBuild your schema from scratch Introspect an existing database to generate schema definitions automatically Introspection is particularly useful if you’re transitioning from an ORM-managed database to a structured schema-as-code approach. This feature is highlighted in Declarative Workflows - Schema inspection\n$ atlas schema inspect -u \"postgres://user:pass@localhost:5432/database?search_path=public\u0026sslmode=disable\" Here’s an example of a minimal schema with two tables using AtlasGO:\ntable \"papers\" { schema = schema.public column \"id\" { type = serial } column \"title\" { type = varchar(255) null = false } primary_key { columns = [column.id] } } table \"mentions\" { schema = schema.public column \"id\" { type = serial } column \"paper_id\" { type = int null = false } column \"document\" { type = text null = false } primary_key { columns = [column.id] } foreign_key \"mentions_paper_fk\" { columns = [column.paper_id] ref_columns = [table.papers.column.id] on_delete = \"CASCADE\" } } This schema defines:\nA papers table with an id (primary key) and title A mentions table that references papers, linking a mention to a paper $ atlas schema apply -u \"postgres://user:pass@db:5432/local_db?sslmode=disable\" --file file://schema/schema.hcl --auto-approve Planning migration statements (2 in total): -- create \"papers\" table: -\u003e CREATE TABLE \"public\".\"papers\" ( \"id\" serial NOT NULL, \"title\" character varying(255) NOT NULL, PRIMARY KEY (\"id\") ); -- create \"mentions\" table: -\u003e CREATE TABLE \"public\".\"mentions\" ( \"id\" serial NOT NULL, \"paper_id\" integer NOT NULL, \"document\" text NOT NULL, PRIMARY KEY (\"id\"), CONSTRAINT \"mentions_paper_fk\" FOREIGN KEY (\"paper_id\") REFERENCES \"public\".\"papers\" (\"id\") ON DELETE CASCADE ); ------------------------------------------- Applying approved migration (2 statements in total): -- create \"papers\" table -\u003e CREATE TABLE \"public\".\"papers\" ( \"id\" serial NOT NULL, \"title\" character varying(255) NOT NULL, PRIMARY KEY (\"id\") ); -- ok (24.597527ms) -- create \"mentions\" table -\u003e CREATE TABLE \"public\".\"mentions\" ( \"id\" serial NOT NULL, \"paper_id\" integer NOT NULL, \"document\" text NOT NULL, PRIMARY KEY (\"id\"), CONSTRAINT \"mentions_paper_fk\" FOREIGN KEY (\"paper_id\") REFERENCES \"public\".\"papers\" (\"id\") ON DELETE CASCADE ); -- ok (5.336047ms) ------------------------- -- 10.896794ms -- 1 migration -- 2 sql statements Adding migrations:\nOnce the schema is defined, making changes is straightforward. Here’s an example migration adding a new column to papers:\nmigration \"add_author\" { table \"papers\" { add column \"author\" { type: text } } } This keeps the database in sync with schema changes, making modifications structured and predictable.\nVisualization:\nFor database visualization, tools like ChartDB.io can generate schema diagrams, making it easier to understand relationships and structures.\nI still need to dive a bit more in the tool but we would end up using a single query with a pretty representation of our schema.\nIn the next section, we’ll discuss best practices for user roles and access control in SQL databases.\nStop using the master user ! RBAC: Creating standard roles and users\nOne of the most overlooked yet impactful improvements you can make to your database setup is role separation. In local development, you might get away with using the postgres or admin user. But in production? That’s a ticking time bomb.\nRole-based access control (RBAC) ensures that each piece of your stack interacts with the database with only the privileges it needs—nothing more, nothing less.\nWhy and how Relying on the master user in production environments is a common anti-pattern. Here’s why it’s problematic:\nSecurity risk: The master user has full access. A compromised app or leaked secret means game over. No visibility: All traffic appears to come from a single user. Debugging and auditing become much harder. Credential management hell: Rotating the master user’s password without breaking everything is a pain unless you’re wired up with something like AWS Secrets Manager which comes at a price. Instead, creating specific users for different concerns allows you to:\nSet resource limits like max query duration or connection count. Leverage monitoring tools (e.g., RDS Enhanced Monitoring or pg_stat_statements) to attribute usage and performance bottlenecks to the correct app. Simplify auditing and anomaly detection. Default go-to roles Here’s a standard setup that works well in most projects:\nRole Privileges Purpose migration_user CREATE, ALTER, DROP Runs schema migrations via CI/CD app_user SELECT, INSERT, UPDATE, DELETE Used by the main application analytics_user SELECT only Read-only access for BI tools, analysts, etc. Only one migration user per environment should exist, and its usage should be limited to your CI/CD pipelines (e.g., GitHub Actions, GitLab CI, etc.).\nA step beyond: match applications with roles Once you have basic role separation, you can go even further by assigning access based on parts of your schema.\nFor example:\nApp A gets read/write on the orders schema. App B can only read from the public schema. A shared database supports multiple services, each with tightly scoped permissions. This works especially well when pairing with application names passed via the PostgreSQL ?application_name= connection parameter. Tools like pg_stat_activity and pg_stat_statements can then help you trace queries back to their origin.\n📝 I love relying on query parameters when working with Databases, especially for Tracking purpose as described in Tracking Row Level changes in PostgreSQL.\n-- Create the migration user CREATE ROLE migration_user WITH LOGIN PASSWORD 'your-secure-password' CREATEDB CREATEROLE NOSUPERUSER; -- Grant schema modification privileges GRANT CONNECT ON DATABASE your_database TO migration_user; GRANT USAGE ON SCHEMA public TO migration_user; GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO migration_user; GRANT ALL PRIVILEGES ON ALL SEQUENCES IN SCHEMA public TO migration_user; -- Create the application user CREATE ROLE app_user WITH LOGIN PASSWORD 'your-secure-password' NOSUPERUSER NOCREATEDB NOCREATEROLE; GRANT CONNECT ON DATABASE your_database TO app_user; GRANT USAGE ON SCHEMA public TO app_user; GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user; -- Create the analytics user CREATE ROLE analytics_user WITH LOGIN PASSWORD 'your-secure-password' NOSUPERUSER NOCREATEDB NOCREATEROLE; GRANT CONNECT ON DATABASE your_database TO analytics_user; GRANT USAGE ON SCHEMA public TO analytics_user; GRANT SELECT ON ALL TABLES IN SCHEMA public TO analytics_user; -- Set default privileges for app_user ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO app_user; -- For analytics_user ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO analytics_user; This example script ensures your roles are ready for day-to-day use, while keeping privileges scoped and secure.\nMore complex setups could rely on more roles, have dedicated roles for users, leverage row-level security or even embrace cloud integration like the IAM Database authentication.\nLet’s now take a look at how we can automate the day 2 lifecycle of our database using a proper CICD workflow !\nMaintaining our database You’re here for the run part too!\nSetting up a schema and applying best practices around roles is great but it’s not enough. Your database needs to evolve safely, scale affordably and be recoverable in a pinch.\nThis section walks through real-world practices that help you stay production-ready.\nCI/CD Deployment with GitHub Actions Whether your database is public-facing or running inside a private subnet (like AWS RDS in a VPC), schema changes should be handled like any other part of your system: via CI/CD.\nA typical setup might look like:\nBuild a one-off migration container using the latest application revision Push it to ECR Trigger a one-off ECS task to run the migration Wait for success or rollback automatically if something fails You can even use GitHub Actions to orchestrate the ECS task execution and lifecycle.\nA complete example is available on github here with manifests, automations, …\nNice to have: wait for ECS Task to finish:\nIf using ECS, consider leveraging the AWS CLI “waiter” sub commands to monitor your task:\n# wait for our created task to be in the stopped state $ aws ecs wait tasks-stopped --cluster my-cluster --tasks This can help in retrieving the migration status right in the Workflow run.\n⚠️ Heads-up: this can be expensive in GitHub Actions minutes: use it with caution or optimize with shorter polling and early exits.\nGood Practice Migrations should be applied by the migration_user created earlier. Use GitHub Actions triggers on main or release branches. Add a manual rollback mechanism using workflow_dispatch to enable safe rollbacks without reverting code. Keeping it lean: reducing the bill Databases often grow silently until one day your AWS bill screams louder than your SRE.\nSome human friendly cost-saving patterns:\nSeparate analytics from OLTP: Don’t let your app compete with long-running queries for dashboard refreshes Summarize over time: Replace large granular datasets with summary tables, i.e.: keep hourly event logs for a month, but store daily rollups after that Crunch data: Convert high-volume event streams into metric tables like: CREATE TABLE metrics ( event_type TEXT, period DATE, completed_count INT ); You still get insights, with a fraction of the storage cost.\nEnsuring we can recover: snapshots \u0026 DB dumps No setup is complete without a solid backup strategy.\nAutomated RDS snapshots: Perfect for infrastructure-level recovery. Fast, point-in-time, but tied to AWS. Database dumps (e.g., pg_dump): Ideal for portability, seeding test/staging environments, and archiving. Both should coexist. Snapshots for fast infra restore, dumps for controlled imports and auditing. Bonus: Use realistic data safely Tools like Replibyte let you:\nDump production-like data into staging/dev environments. Anonymize sensitive data automatically. Safely run integration or load tests without risking exposure. This improves test coverage while respecting privacy and compliance.\nConclusion Bootstrapping and maintaining SQL databases doesn’t have to be a mystery or a manual chore. By treating infrastructure and schema as code, defining clear roles, and integrating database changes into your CI/CD workflows, you build a system that is reproducible, secure, and scalable by design.\nThis hands-on approach not only improves developer velocity but also strengthens operational resilience. Whether you’re spinning up a new service locally, managing production-grade RDS instances or fine-tuning query access for analytics, these practices help you move fast without breaking your data.\nFeel free to reach out if you have feedbacks or questions !\nTheo “Bob” Massard\nIt’s always postgres ↩︎\nmany tools like alembic which I loved so much in the past that I tried to work around the python-first migration declaration in alembic-sequeled a few years back ↩︎\n","wordCount":"2058","inLanguage":"en","image":"https://blog.tbobm.dev/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-04-18T21:30:00+02:00","dateModified":"2025-04-18T21:30:00+02:00","author":{"@type":"Person","name":"Theo \"Bob\" Massard"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.tbobm.dev/posts/db-bootstrapping/"},"publisher":{"@type":"Organization","name":"tbobm.dev","logo":{"@type":"ImageObject","url":"https://blog.tbobm.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.tbobm.dev/ accesskey=h title="tbobm.dev (Alt + H)">tbobm.dev</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.tbobm.dev/about/ title=about><span>about</span></a></li><li><a href=https://blog.tbobm.dev/now/ title=now><span>now</span></a></li><li><a href=https://blog.tbobm.dev/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.tbobm.dev/>Home</a>&nbsp;»&nbsp;<a href=https://blog.tbobm.dev/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Bootstrapping SQL databases for local and production setup</h1><div class=post-meta><span title='2025-04-18 21:30:00 +0200 +0200'>April 18, 2025</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;2058 words&nbsp;·&nbsp;Theo "Bob" Massard&nbsp;|&nbsp;<a href=https://github.com/tbobm/tbobm-blog/content/posts/db-bootstrapping/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#infra-as-code-schema-as-code-everything-as-code>Infra as Code, Schema as Code, Everything as Code</a><ul><li><a href=#why-yet-another-tool>Why yet another tool?</a></li><li><a href=#embrace-schema-as-code>Embrace schema as code</a></li></ul></li><li><a href=#stop-using-the-master-user->Stop using the master user !</a><ul><li><a href=#why-and-how>Why and how</a></li><li><a href=#default-go-to-roles>Default go-to roles</a></li><li><a href=#a-step-beyond-match-applications-with-roles>A step beyond: match applications with roles</a></li></ul></li><li><a href=#maintaining-our-database>Maintaining our database</a><ul><li><a href=#cicd-deployment-with-github-actions>CI/CD Deployment with GitHub Actions</a></li><li><a href=#keeping-it-lean-reducing-the-bill>Keeping it lean: reducing the bill</a></li><li><a href=#ensuring-we-can-recover-snapshots--db-dumps>Ensuring we can recover: snapshots & DB dumps</a></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></nav></div></details></div><div class=post-content><p>A practical walkthrough of how I manage SQL databases across dev and
prod - from local Docker setups to CI/CD-powered migrations in the cloud.</p><h2 id=intro>Intro<a hidden class=anchor aria-hidden=true href=#intro>#</a></h2><p>When working with databases, it’s easy to fall into the trap of taking shortcuts — a
quick container here, a few clicks in the AWS console there, and before
you know it, you&rsquo;re running production off an unversioned schema with the master user.</p><p>This article is a hands-on guide—and a collection of things I’ve grown to
enjoy when working with SQL databases in modern environments. It covers
setting up <a href=https://www.postgresql.org/>Postgres</a> <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> both locally and in the cloud, adopting schema as
code using <a href=https://atlasgo.io/>Atlas</a>, securing access with proper roles, and maintaining
everything through <a href=https://github.com/features/actions>GitHub Actions</a>.</p><p>The goal is to keep your database setup repeatable, reviewable, and resilient from day one.</p><h2 id=infra-as-code-schema-as-code-everything-as-code>Infra as Code, Schema as Code, Everything as Code<a hidden class=anchor aria-hidden=true href=#infra-as-code-schema-as-code-everything-as-code>#</a></h2><p>When working with databases, consistency and repeatability are key. Whether
setting up a local development database or provisioning a production-ready environment,
managing infrastructure and schema as code ensures a predictable and
maintainable setup.</p><p>Let&rsquo;s explore why this approach matters and how tools
like <a href=https://atlasgo.io/>AtlasGO</a> simplify schema management.</p><h3 id=why-yet-another-tool>Why yet another tool?<a hidden class=anchor aria-hidden=true href=#why-yet-another-tool>#</a></h3><p>There are plenty of database migration tools out there, like Alembic that I&rsquo;ve used in the past
but I love AtlasGO for a few reasons:</p><ul><li><strong>Schema as Code</strong>: unlike imperative migration tools, <a href=https://github.com/ariga/atlas>AtlasGO</a> takes a
declarative approach, allowing you to define your schema in a structured format.</li><li><strong>Leverages HCL</strong>: it uses HashiCorp Configuration Language (<a href=https://github.com/hashicorp/hcl>HCL</a>), the same format used
by (my dear) Terraform and Packer, making it easier to integrate with existing
infrastructure as code workflows.</li><li><strong>No dependecy on a language dependency</strong>: many tools require Python <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>, Java,
or SQL-based scripting. AtlasGO avoids this, keeping the setup lightweight and easy to use.</li><li><strong>Easy to replicate and review</strong>: having a single source of truth for schema definitions
makes collaboration, code reviews, and automation seamless.</li></ul><p><strong>No ClickOps</strong>: I strongly dislike manual UI-based configurations (aka <a href=https://en.wiktionary.org/wiki/ClickOps>ClickOps</a>).
They lead to inconsistencies and make infrastructure difficult to track and reproduce.</p><p><em>What this means in practice?</em></p><p>By adopting a declarative approach, we gain:</p><p><strong>Predictability</strong>: changes are explicit and version-controlled.</p><p><strong>Automation</strong>: infrastructure and schema changes can be applied programmatically.</p><p><strong>Scalability</strong>: the same process can be used across local, staging, and production environments.</p><p>In the next section, we’ll get hands-on with [AtlasGO][atlas-main], defining an initial schema
and managing database migrations efficiently.</p><h3 id=embrace-schema-as-code>Embrace schema as code<a hidden class=anchor aria-hidden=true href=#embrace-schema-as-code>#</a></h3><p><strong>Initial schema declaration:</strong></p><p>When starting with schema as code, you can either:</p><ul><li>Build your schema from scratch</li><li>Introspect an existing database to generate schema definitions automatically</li></ul><p>Introspection is particularly useful if you&rsquo;re transitioning from an ORM-managed
database to a structured schema-as-code approach. This feature is highlighted in
<a href=https://atlasgo.io/declarative/inspect>Declarative Workflows - Schema inspection</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> atlas schema inspect -u <span class=s2>&#34;postgres://user:pass@localhost:5432/database?search_path=public&amp;sslmode=disable&#34;</span>
</span></span></code></pre></div><p>Here’s an example of a minimal schema with two tables using <a href=https://atlasgo.io/>AtlasGO</a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-hcl data-lang=hcl><span class=line><span class=cl><span class=k>table</span> <span class=s2>&#34;papers&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  schema</span> <span class=o>=</span> <span class=k>schema</span><span class=p>.</span><span class=k>public</span>
</span></span><span class=line><span class=cl>  <span class=k>column</span> <span class=s2>&#34;id&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>    type</span> <span class=o>=</span> <span class=k>serial</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>  <span class=k>column</span> <span class=s2>&#34;title&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>    type</span> <span class=o>=</span> <span class=k>varchar</span><span class=p>(</span><span class=m>255</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>    null</span> <span class=o>=</span> <span class=kt>false</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>  <span class=k>primary_key</span> {
</span></span><span class=line><span class=cl><span class=n>    columns</span> <span class=o>=</span> <span class=p>[</span><span class=k>column</span><span class=p>.</span><span class=k>id</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>}
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>table</span> <span class=s2>&#34;mentions&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>  schema</span> <span class=o>=</span> <span class=k>schema</span><span class=p>.</span><span class=k>public</span>
</span></span><span class=line><span class=cl>  <span class=k>column</span> <span class=s2>&#34;id&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>    type</span> <span class=o>=</span> <span class=k>serial</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>  <span class=k>column</span> <span class=s2>&#34;paper_id&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>    type</span> <span class=o>=</span> <span class=k>int</span>
</span></span><span class=line><span class=cl><span class=n>    null</span> <span class=o>=</span> <span class=kt>false</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>  <span class=k>column</span> <span class=s2>&#34;document&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>    type</span> <span class=o>=</span> <span class=k>text</span>
</span></span><span class=line><span class=cl><span class=n>    null</span> <span class=o>=</span> <span class=kt>false</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>  <span class=k>primary_key</span> {
</span></span><span class=line><span class=cl><span class=n>    columns</span> <span class=o>=</span> <span class=p>[</span><span class=k>column</span><span class=p>.</span><span class=k>id</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>foreign_key</span> <span class=s2>&#34;mentions_paper_fk&#34;</span> {
</span></span><span class=line><span class=cl><span class=n>    columns</span> <span class=o>=</span> <span class=p>[</span><span class=k>column</span><span class=p>.</span><span class=k>paper_id</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>    ref_columns</span> <span class=o>=</span> <span class=p>[</span><span class=k>table</span><span class=p>.</span><span class=k>papers</span><span class=p>.</span><span class=k>column</span><span class=p>.</span><span class=k>id</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>    on_delete</span> <span class=o>=</span> <span class=s2>&#34;CASCADE&#34;</span>
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><p>This schema defines:</p><ul><li>A <code>papers</code> table with an id (primary key) and title</li><li>A <code>mentions</code> table that references papers, linking a mention to a paper</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> atlas schema apply -u <span class=s2>&#34;postgres://user:pass@db:5432/local_db?sslmode=disable&#34;</span> --file file://schema/schema.hcl --auto-approve
</span></span><span class=line><span class=cl><span class=go>Planning migration statements (2 in total):
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>  -- create &#34;papers&#34; table:
</span></span></span><span class=line><span class=cl><span class=go>    -&gt; CREATE TABLE &#34;public&#34;.&#34;papers&#34; (
</span></span></span><span class=line><span class=cl><span class=go>         &#34;id&#34; serial NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         &#34;title&#34; character varying(255) NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         PRIMARY KEY (&#34;id&#34;)
</span></span></span><span class=line><span class=cl><span class=go>       );
</span></span></span><span class=line><span class=cl><span class=go>  -- create &#34;mentions&#34; table:
</span></span></span><span class=line><span class=cl><span class=go>    -&gt; CREATE TABLE &#34;public&#34;.&#34;mentions&#34; (
</span></span></span><span class=line><span class=cl><span class=go>         &#34;id&#34; serial NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         &#34;paper_id&#34; integer NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         &#34;document&#34; text NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         PRIMARY KEY (&#34;id&#34;),
</span></span></span><span class=line><span class=cl><span class=go>         CONSTRAINT &#34;mentions_paper_fk&#34; FOREIGN KEY (&#34;paper_id&#34;) REFERENCES &#34;public&#34;.&#34;papers&#34; (&#34;id&#34;) ON DELETE CASCADE
</span></span></span><span class=line><span class=cl><span class=go>       );
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>-------------------------------------------
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>Applying approved migration (2 statements in total):
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>  -- create &#34;papers&#34; table
</span></span></span><span class=line><span class=cl><span class=go>    -&gt; CREATE TABLE &#34;public&#34;.&#34;papers&#34; (
</span></span></span><span class=line><span class=cl><span class=go>         &#34;id&#34; serial NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         &#34;title&#34; character varying(255) NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         PRIMARY KEY (&#34;id&#34;)
</span></span></span><span class=line><span class=cl><span class=go>       );
</span></span></span><span class=line><span class=cl><span class=go>  -- ok (24.597527ms)
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>  -- create &#34;mentions&#34; table
</span></span></span><span class=line><span class=cl><span class=go>    -&gt; CREATE TABLE &#34;public&#34;.&#34;mentions&#34; (
</span></span></span><span class=line><span class=cl><span class=go>         &#34;id&#34; serial NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         &#34;paper_id&#34; integer NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         &#34;document&#34; text NOT NULL,
</span></span></span><span class=line><span class=cl><span class=go>         PRIMARY KEY (&#34;id&#34;),
</span></span></span><span class=line><span class=cl><span class=go>         CONSTRAINT &#34;mentions_paper_fk&#34; FOREIGN KEY (&#34;paper_id&#34;) REFERENCES &#34;public&#34;.&#34;papers&#34; (&#34;id&#34;) ON DELETE CASCADE
</span></span></span><span class=line><span class=cl><span class=go>       );
</span></span></span><span class=line><span class=cl><span class=go>  -- ok (5.336047ms)
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>  -------------------------
</span></span></span><span class=line><span class=cl><span class=go>  -- 10.896794ms
</span></span></span><span class=line><span class=cl><span class=go>  -- 1 migration
</span></span></span><span class=line><span class=cl><span class=go>  -- 2 sql statements
</span></span></span></code></pre></div><p><strong>Adding migrations:</strong></p><p>Once the schema is defined, making changes is straightforward.
Here’s an example migration adding a new column to papers:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-hcl data-lang=hcl><span class=line><span class=cl><span class=k>migration</span> <span class=s2>&#34;add_author&#34;</span> {
</span></span><span class=line><span class=cl>  <span class=k>table</span> <span class=s2>&#34;papers&#34;</span> {
</span></span><span class=line><span class=cl>    <span class=k>add</span> <span class=k>column</span> <span class=s2>&#34;author&#34;</span> { <span class=k>type</span><span class=err>:</span> <span class=k>text</span> }
</span></span><span class=line><span class=cl>  }
</span></span><span class=line><span class=cl>}
</span></span></code></pre></div><p>This keeps the database in sync with schema changes, making
modifications structured and predictable.</p><p><strong>Visualization:</strong></p><p>For database visualization, tools like ChartDB.io can generate schema diagrams,
making it easier to understand relationships and structures.</p><p>I still need to dive a bit more in the tool but we would end up using a
single query with a pretty representation of our schema.</p><p><img loading=lazy src=./db-graph.png alt=chartdb-view></p><p>In the next section, we’ll discuss best practices for user roles
and access control in SQL databases.</p><h2 id=stop-using-the-master-user->Stop using the master user !<a hidden class=anchor aria-hidden=true href=#stop-using-the-master-user->#</a></h2><p><em>RBAC: Creating standard roles and users</em></p><p>One of the most overlooked yet impactful improvements you can make to your
database setup is role separation. In local development, you might get away
with using the <code>postgres</code> or <code>admin</code> user. But in production? That’s a ticking time bomb.</p><p>Role-based access control (RBAC) ensures that each piece of your stack interacts with
the database with only the privileges it needs—nothing more, nothing less.</p><h3 id=why-and-how>Why and how<a hidden class=anchor aria-hidden=true href=#why-and-how>#</a></h3><p>Relying on the master user in production environments is a common anti-pattern.
Here&rsquo;s why it&rsquo;s problematic:</p><ul><li><strong>Security risk</strong>: The master user has full access. A compromised app or
leaked secret means game over.</li><li><strong>No visibility</strong>: All traffic appears to come from a single user.
Debugging and auditing become much harder.</li><li><strong>Credential management hell</strong>: Rotating the master user&rsquo;s password
without breaking everything is a pain unless you&rsquo;re wired up
with something like AWS Secrets Manager which comes at a price.</li></ul><p>Instead, creating specific users for different concerns allows you to:</p><ul><li>Set <strong>resource limits</strong> like max query duration or connection count.</li><li>Leverage <strong>monitoring tools</strong> (e.g., RDS Enhanced Monitoring or <code>pg_stat_statements</code>)
to attribute usage and performance bottlenecks to the correct app.</li><li>Simplify auditing and anomaly detection.</li></ul><h3 id=default-go-to-roles>Default go-to roles<a hidden class=anchor aria-hidden=true href=#default-go-to-roles>#</a></h3><p>Here’s a standard setup that works well in most projects:</p><table><thead><tr><th>Role</th><th>Privileges</th><th>Purpose</th></tr></thead><tbody><tr><td><code>migration_user</code></td><td><code>CREATE</code>, <code>ALTER</code>, <code>DROP</code></td><td>Runs schema migrations via CI/CD</td></tr><tr><td><code>app_user</code></td><td><code>SELECT</code>, <code>INSERT</code>, <code>UPDATE</code>, <code>DELETE</code></td><td>Used by the main application</td></tr><tr><td><code>analytics_user</code></td><td><code>SELECT</code> only</td><td>Read-only access for BI tools, analysts, etc.</td></tr></tbody></table><p>Only <strong>one migration user per environment</strong> should exist, and its usage should be limited to
your CI/CD pipelines (e.g., GitHub Actions, GitLab CI, etc.).</p><h3 id=a-step-beyond-match-applications-with-roles>A step beyond: match applications with roles<a hidden class=anchor aria-hidden=true href=#a-step-beyond-match-applications-with-roles>#</a></h3><p>Once you have basic role separation, you can go even further by assigning access based on <em>parts</em> of your schema.</p><p>For example:</p><ul><li>App A gets read/write on the <code>orders</code> schema.</li><li>App B can only read from the <code>public</code> schema.</li><li>A shared database supports multiple services, each with tightly scoped permissions.</li></ul><p>This works especially well when pairing with application names passed via the PostgreSQL
<code>?application_name=</code> connection parameter. Tools like <code>pg_stat_activity</code> and <code>pg_stat_statements</code>
can then help you trace queries back to their origin.</p><blockquote><p>📝 I love relying on query parameters when working with Databases, especially for Tracking
purpose as described in <a href=https://medium.com/@tbobm/tracking-row-level-changes-in-postgresql-4455f91ab8d1>Tracking Row Level changes in PostgreSQL</a>.</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Create the migration user
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>ROLE</span><span class=w> </span><span class=n>migration_user</span><span class=w> </span><span class=k>WITH</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>LOGIN</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>PASSWORD</span><span class=w> </span><span class=s1>&#39;your-secure-password&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>CREATEDB</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>CREATEROLE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>NOSUPERUSER</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Grant schema modification privileges
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>GRANT</span><span class=w> </span><span class=k>CONNECT</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>DATABASE</span><span class=w> </span><span class=n>your_database</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>migration_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>USAGE</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>migration_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>ALL</span><span class=w> </span><span class=k>PRIVILEGES</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>ALL</span><span class=w> </span><span class=n>TABLES</span><span class=w> </span><span class=k>IN</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>migration_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>ALL</span><span class=w> </span><span class=k>PRIVILEGES</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>ALL</span><span class=w> </span><span class=n>SEQUENCES</span><span class=w> </span><span class=k>IN</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>migration_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Create the application user
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>ROLE</span><span class=w> </span><span class=n>app_user</span><span class=w> </span><span class=k>WITH</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>LOGIN</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>PASSWORD</span><span class=w> </span><span class=s1>&#39;your-secure-password&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>NOSUPERUSER</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>NOCREATEDB</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>NOCREATEROLE</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>CONNECT</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>DATABASE</span><span class=w> </span><span class=n>your_database</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>app_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>USAGE</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>app_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>SELECT</span><span class=p>,</span><span class=w> </span><span class=k>INSERT</span><span class=p>,</span><span class=w> </span><span class=k>UPDATE</span><span class=p>,</span><span class=w> </span><span class=k>DELETE</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>ALL</span><span class=w> </span><span class=n>TABLES</span><span class=w> </span><span class=k>IN</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>app_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Create the analytics user
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>CREATE</span><span class=w> </span><span class=k>ROLE</span><span class=w> </span><span class=n>analytics_user</span><span class=w> </span><span class=k>WITH</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>LOGIN</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>PASSWORD</span><span class=w> </span><span class=s1>&#39;your-secure-password&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>NOSUPERUSER</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>NOCREATEDB</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>NOCREATEROLE</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>CONNECT</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>DATABASE</span><span class=w> </span><span class=n>your_database</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>analytics_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>USAGE</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>analytics_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>SELECT</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=k>ALL</span><span class=w> </span><span class=n>TABLES</span><span class=w> </span><span class=k>IN</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>analytics_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Set default privileges for app_user
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>ALTER</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=k>PRIVILEGES</span><span class=w> </span><span class=k>IN</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>SELECT</span><span class=p>,</span><span class=w> </span><span class=k>INSERT</span><span class=p>,</span><span class=w> </span><span class=k>UPDATE</span><span class=p>,</span><span class=w> </span><span class=k>DELETE</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=n>TABLES</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>app_user</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- For analytics_user
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>ALTER</span><span class=w> </span><span class=k>DEFAULT</span><span class=w> </span><span class=k>PRIVILEGES</span><span class=w> </span><span class=k>IN</span><span class=w> </span><span class=k>SCHEMA</span><span class=w> </span><span class=k>public</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GRANT</span><span class=w> </span><span class=k>SELECT</span><span class=w> </span><span class=k>ON</span><span class=w> </span><span class=n>TABLES</span><span class=w> </span><span class=k>TO</span><span class=w> </span><span class=n>analytics_user</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p>This example script ensures your roles are ready for day-to-day use, while
keeping privileges scoped and secure.</p><p>More complex setups could rely on more roles, have dedicated roles for
users, leverage <a href=https://www.postgresql.org/docs/current/ddl-rowsecurity.html>row-level security</a> or even embrace cloud integration
like the <a href=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html>IAM Database authentication</a>.</p><p>Let&rsquo;s now take a look at how we can automate the day 2 lifecycle of our database
using a proper CICD workflow !</p><h2 id=maintaining-our-database>Maintaining our database<a hidden class=anchor aria-hidden=true href=#maintaining-our-database>#</a></h2><p><em>You&rsquo;re here for the <strong>run</strong> part too!</em></p><p>Setting up a schema and applying best practices around roles
is great but it’s not enough. Your database needs to <strong>evolve</strong> safely,
<strong>scale</strong> affordably and be <strong>recoverable</strong> in a pinch.</p><p>This section walks through real-world practices that help you stay production-ready.</p><h3 id=cicd-deployment-with-github-actions>CI/CD Deployment with GitHub Actions<a hidden class=anchor aria-hidden=true href=#cicd-deployment-with-github-actions>#</a></h3><p>Whether your database is public-facing or running inside a private subnet
(like AWS RDS in a VPC), schema changes should be handled like any
other part of your system: via CI/CD.</p><p>A typical setup might look like:</p><ol><li><strong>Build a one-off migration container</strong> using the latest application revision</li><li><strong>Push it to ECR</strong></li><li><strong>Trigger a one-off ECS task</strong> to run the migration</li><li><strong>Wait for success or rollback</strong> automatically if something fails</li></ol><p>You can even use GitHub Actions to orchestrate the ECS task execution and lifecycle.</p><p>A complete example is available <a href=https://github.com/tbobm/bootstrapping-databases-for-local-and-prod>on github <strong>here</strong></a> with
manifests, automations, &mldr;</p><p><img loading=lazy src=./db-migration.png alt="migration workflow"></p><p><strong>Nice to have: wait for ECS Task to finish:</strong></p><p>If using <a href=https://docs.aws.amazon.com/AmazonECS/latest/developerguide/Welcome.html>ECS</a>, consider leveraging the AWS CLI &ldquo;waiter&rdquo; sub commands to monitor
your task:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># wait for our created task to be in the stopped state</span>
</span></span><span class=line><span class=cl>$ aws ecs <span class=nb>wait</span> tasks-stopped --cluster my-cluster --tasks &lt;task-id&gt;
</span></span></code></pre></div><p>This can help in retrieving the migration status right in the Workflow run.</p><blockquote><p>⚠️ Heads-up: this can be expensive in GitHub Actions minutes: use it with caution or optimize with shorter polling and early exits.</p></blockquote><h4 id=good-practice>Good Practice<a hidden class=anchor aria-hidden=true href=#good-practice>#</a></h4><ul><li>Migrations should be applied by the <code>migration_user</code> created earlier.</li><li>Use GitHub Actions triggers on <code>main</code> or <code>release</code> branches.</li><li>Add a <strong>manual rollback</strong> mechanism using <code>workflow_dispatch</code> to enable safe rollbacks without reverting code.</li></ul><h3 id=keeping-it-lean-reducing-the-bill>Keeping it lean: reducing the bill<a hidden class=anchor aria-hidden=true href=#keeping-it-lean-reducing-the-bill>#</a></h3><p>Databases often grow silently until one day your AWS bill screams louder than your SRE.</p><p><strong>Some human friendly cost-saving patterns</strong>:</p><ul><li><strong>Separate analytics from OLTP</strong>: Don&rsquo;t let your app compete with long-running queries for dashboard refreshes</li><li><strong>Summarize over time</strong>: Replace large granular datasets with summary tables,
i.e.: keep hourly event logs for a month, but store daily rollups after that</li><li><strong>Crunch data</strong>: Convert high-volume event streams into metric tables like:</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>CREATE</span><span class=w> </span><span class=k>TABLE</span><span class=w> </span><span class=n>metrics</span><span class=w> </span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>event_type</span><span class=w> </span><span class=nb>TEXT</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>period</span><span class=w> </span><span class=nb>DATE</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>completed_count</span><span class=w> </span><span class=nb>INT</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><p>You still get insights, with a fraction of the storage cost.</p><h3 id=ensuring-we-can-recover-snapshots--db-dumps>Ensuring we can recover: snapshots & DB dumps<a hidden class=anchor aria-hidden=true href=#ensuring-we-can-recover-snapshots--db-dumps>#</a></h3><p>No setup is complete without a solid backup strategy.</p><ul><li><strong>Automated RDS snapshots</strong>: Perfect for infrastructure-level recovery. Fast, point-in-time, but tied to AWS.</li><li><strong>Database dumps</strong> (e.g., <code>pg_dump</code>): Ideal for portability, seeding test/staging environments, and archiving.</li><li><strong>Both</strong> should coexist. Snapshots for fast infra restore, dumps for controlled imports and auditing.</li></ul><h4 id=bonus-use-realistic-data-safely>Bonus: Use realistic data safely<a hidden class=anchor aria-hidden=true href=#bonus-use-realistic-data-safely>#</a></h4><p>Tools like <a href=https://github.com/Qovery/Replibyte>Replibyte</a> let you:</p><ul><li>Dump production-like data into staging/dev environments.</li><li><strong>Anonymize sensitive data</strong> automatically.</li><li>Safely run integration or load tests without risking exposure.</li></ul><p>This improves test coverage while respecting privacy and compliance.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Bootstrapping and maintaining SQL databases doesn&rsquo;t have to be a mystery or a manual chore.
By treating infrastructure and schema as code, defining clear roles, and integrating database
changes into your CI/CD workflows, you build a system that is reproducible, secure, and scalable
by design.</p><p>This hands-on approach not only improves developer velocity but also strengthens
operational resilience. Whether you&rsquo;re spinning up a new service locally,
managing production-grade RDS instances or fine-tuning query access for analytics,
these practices help you move fast without breaking your data.</p><p>Feel free to reach out if you have feedbacks or questions !</p><p><a href=https://linkedin.com/in/tbobm/>Theo &ldquo;Bob&rdquo; Massard</a></p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>It&rsquo;s always postgres&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>many tools like <a href=https://github.com/sqlalchemy/alembic>alembic</a> which I loved so much in the past that I
tried to work around the python-first migration declaration in <a href=https://github.com/tbobm/alembic-sequeled>alembic-sequeled</a>
a few years back&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.tbobm.dev/tags/tech/>Tech</a></li><li><a href=https://blog.tbobm.dev/tags/database/>Database</a></li><li><a href=https://blog.tbobm.dev/tags/rbac/>Rbac</a></li><li><a href=https://blog.tbobm.dev/tags/postgres/>Postgres</a></li><li><a href=https://blog.tbobm.dev/tags/migration/>Migration</a></li></ul><nav class=paginav><a class=next href=https://blog.tbobm.dev/posts/complete-health-checks/><span class=title>Next »</span><br><span>Complete health checks and why they matter</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.tbobm.dev/>tbobm.dev</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>